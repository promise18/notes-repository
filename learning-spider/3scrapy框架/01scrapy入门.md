# Scrapy入门

![1562725019648](D:\笔记\爬虫\3scrapy框架\01scrapy入门.assets\1562725019648.png)

![1562723959979](D:\笔记\爬虫\3scrapy框架\01scrapy入门.assets\1562723959979.png)

![1562723994831](D:\笔记\爬虫\3scrapy框架\01scrapy入门.assets\1562723994831.png)

![1562724672354](D:\笔记\爬虫\3scrapy框架\01scrapy入门.assets\1562724672354.png)

![1562725106074](D:\笔记\爬虫\3scrapy框架\01scrapy入门.assets\1562725106074.png)

笔记：

## 创建项目和爬虫

1. 创建项目：`scrapy startproject [爬虫的名字]`。
2. 创建爬虫：进入到项目所在的路径，执行命令：`scrapy genspider [爬虫名字] [爬虫的域名]。`注意，爬虫名字不能和项目名称一致

## 项目目录结构

见上

# CrawlSipder

![1562742079888](01scrapy入门.assets/1562742079888.png)

==**这里是-t**==

![1562742118765](D:\笔记\爬虫\3scrapy框架\01scrapy入门.assets\1562742118765.png)

![1562742134826](01scrapy入门.assets/1562742134826.png)

allow 和 deny用的比较多。

![1562742173024](D:\笔记\爬虫\3scrapy框架\01scrapy入门.assets\1562742173024.png)

# Scrapy Shell

![1562745041872](01scrapy入门.assets\1562745041872.png)

![1562813028370](01scrapy入门.assets/1562813028370.png)

# Request对象

![1562812804603](01scrapy入门.assets/1562812804603.png)

# Response对象

![1562812836987](01scrapy入门.assets/1562812836987.png)

![1562812950957](01scrapy入门.assets/1562812950957.png)

