{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8939468c3cf9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Developer_tools\\Anaconda3\\envs\\tfgpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Developer_tools\\Anaconda3\\envs\\tfgpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Developer_tools\\Anaconda3\\envs\\tfgpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Developer_tools\\Anaconda3\\envs\\tfgpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Developer_tools\\Anaconda3\\envs\\tfgpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-2-8939468c3cf9>:23: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Iter0,Testing Accuacy0.9001\n",
      "Iter1,Testing Accuacy0.9107\n",
      "Iter2,Testing Accuacy0.9178\n",
      "Iter3,Testing Accuacy0.9192\n",
      "Iter4,Testing Accuacy0.9235\n",
      "Iter5,Testing Accuacy0.9247\n",
      "Iter6,Testing Accuacy0.9241\n",
      "Iter7,Testing Accuacy0.9276\n",
      "Iter8,Testing Accuacy0.9282\n",
      "Iter9,Testing Accuacy0.9289\n",
      "Iter10,Testing Accuacy0.9287\n",
      "Iter11,Testing Accuacy0.9283\n",
      "Iter12,Testing Accuacy0.9303\n",
      "Iter13,Testing Accuacy0.9299\n",
      "Iter14,Testing Accuacy0.9299\n",
      "Iter15,Testing Accuacy0.9289\n",
      "Iter16,Testing Accuacy0.9293\n",
      "Iter17,Testing Accuacy0.9315\n",
      "Iter18,Testing Accuacy0.9314\n",
      "Iter19,Testing Accuacy0.9325\n",
      "Iter20,Testing Accuacy0.9323\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)# one_hot:把标签转换为只有0和1\n",
    "\n",
    "# 定义每个批次的大小\n",
    "## 可以通过修改批次来进行优化\n",
    "batch_size = 100 # 一次性放入一个批次 \n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size # 整除\n",
    "\n",
    "# 定义两个placeholder\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784]) # 28 * 28 转换为784\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "## 可以通过增加隐藏层进行优化 ## w和b的初始化值可以修改进行优化\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b) ## 修改激活函数进行优化\n",
    "\n",
    "# 定义二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction)) ## 代价函数：交叉熵会不会更好\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "# 使用梯度下降法\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss) ## 学习率修改进行优化以及其他优化方式\n",
    "# 新的训练方式\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)  # 1e-3：10的-3次方,选择adam的学习率一般选很小\n",
    "# 初始化变量 \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))# argmax 返回一维张量中最大的值所在的位置\n",
    "# 求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) # 如果9个true，1个flase，那么就是9个1，1个0，准确率为90%\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # 把所有的图片训练21次\n",
    "    for epoch in range(21): ## 尝试训练更多的次数进行优化\n",
    "        for batch in range(n_batch): # 一共进行的批次（把训练集中所有的图片都循环了一次）\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)# 获得下一个一百张图片\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}) # 喂进去的就是测试集里面的图片和标签\n",
    "        print(\"Iter\" + str(epoch) + \",Testing Accuacy\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总结：\n",
    "# 1.交叉熵\n",
    "# 2.过拟合定义以及过拟合问题的解决（3种方式） drop\n",
    "# 3.优化器选择 SGD：准确率较高，adam：优化最快"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
